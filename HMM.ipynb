{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10370509",
   "metadata": {},
   "source": [
    "# Hidden Markov Model Implementation\n",
    "\n",
    "#### We essentially will create a model with calculated weights and use that with the Viterbi algorithm to determine the accuracy of a given piano practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b6b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc3172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our model states using MIDI for labeling notes\n",
    "ode15 = [64, 64, 65, 67, 67, 65, 64, 62, 60, 60, 62, 64, 64, 62, 62]\n",
    "beats = [1]*15\n",
    "events = list(zip(ode15, dur_beats))\n",
    "\n",
    "NOTE_NAMES = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235ffbe",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa3a6b",
   "metadata": {},
   "source": [
    "##### We are using the build_hmm_from_beats() method below to essentially create a left-to-right hidden markov model with pre-defined weights that are based upon the CQT fram paramenters.\n",
    "\n",
    "My CQT implementation uses 2 main parameters: hop length and sample rate. There is one spectogram column for every 1 hop length samples. So, the time between two columns is:\n",
    "\n",
    "$dt = \\frac{hoplen}{sr}$ seconds, or $1000 * \\frac{hoplen}{sr}$ milliseconds\n",
    "\n",
    "Secondly, we define a reference/ideal tempo, which in this case is bpm_ref = 120 beats per minute. When we convert this to milliseconds, this means 1 beat = 500 milliseconds. We can then calculate frames per beat to be (ms per beat) / (dt).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed54491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_cqt(audio_path, sr=22050, hop_length=512, fmin=27.5, n_bins=84, bins_per_octave=12):\n",
    "    y, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "\n",
    "    C = librosa.cqt(y, sr=sr, hop_length=hop_length, fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave)\n",
    "    C_mag = np.abs(C)\n",
    "    C_db = librosa.amplitude_to_db(C_mag, ref=np.max)\n",
    "    C_norm = (C_db - C_db.min()) / (C_db.max() - C_db.min() + 1e-8)\n",
    "\n",
    "    return C_norm\n",
    "\n",
    "\n",
    "def dt_ms_from_cqt(sr, hop_length):\n",
    "    return 1000.0 * hop_length / sr\n",
    "\n",
    "\n",
    "def build_hmm_from_beats(pitches, beats, bpm_ref, dt_ms):\n",
    "    assert len(pitches) == len(beats)\n",
    "    ms_per_beat = 60000.0 / bpm_ref\n",
    "    frames_per_beat = ms_per_beat / dt_ms\n",
    "\n",
    "    states = []\n",
    "    for idx, (pitch, dur) in enumerate(zip(pitches, beats)):\n",
    "        dur_steps = max(1, int(round(dur * frames_per_beat)))\n",
    "        states.append({\"idx\": idx, \"pitch\": pitch, \"beats\": dur, \"dur_steps\": dur_steps})\n",
    "\n",
    "    N = len(states)\n",
    "    A = np.zeros((N, N), float)\n",
    "\n",
    "    for i, s in enumerate(states):\n",
    "        if i == N - 1:\n",
    "            A[i, i] = 1.0\n",
    "        else:\n",
    "            p_adv = 1.0 / s[\"dur_steps\"]\n",
    "            A[i, i] = 1.0 - p_adv\n",
    "            A[i, i+1] = p_adv\n",
    "\n",
    "    pi = np.zeros(N); pi[0] = 1.0\n",
    "    return states, A, pi\n",
    "\n",
    "\n",
    "def midi_to_name(m):\n",
    "    return f\"{NOTE_NAMES[m % 12]}{(m // 12) - 1}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56bccd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hmm_model(states, A, dt_ms):\n",
    "    print(\"=== HMM Model ===\")\n",
    "    print(f\"Number of states: {len(states)}\")\n",
    "    print()\n",
    "\n",
    "    for i, s in enumerate(states):\n",
    "        note = midi_to_name(s[\"pitch\"])\n",
    "        dur_frames = s[\"dur_steps\"]\n",
    "        dur_ms = dur_frames * dt_ms\n",
    "        \n",
    "        stay_prob = A[i, i]\n",
    "        adv_prob = A[i, i+1] if i < len(states)-1 else 0.0\n",
    "\n",
    "        print(f\"State {i}: {note}\")\n",
    "        print(f\"  Expected duration: {dur_frames} frames (~{dur_ms:.1f} ms)\")\n",
    "        print(f\"  Transition: stay={stay_prob:.4f}, advance={adv_prob:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d20eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HMM Model ===\n",
      "Number of states: 15\n",
      "\n",
      "State 0: E4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 1: E4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 2: F4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 3: G4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 4: G4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 5: F4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 6: E4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 7: D4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 8: C4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 9: C4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 10: D4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 11: E4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 12: E4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 13: D4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=0.9545, advance=0.0455\n",
      "\n",
      "State 14: D4\n",
      "  Expected duration: 22 frames (~510.8 ms)\n",
      "  Transition: stay=1.0000, advance=0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bpm_ref = 120\n",
    "sr = 22050\n",
    "hop_length = 512\n",
    "dt_ms = dt_ms_from_cqt(sr, hop_length)\n",
    "\n",
    "states, A, pi = build_hmm_from_beats(ode15, beats, bpm_ref, dt_ms)\n",
    "print_hmm_model(states, A, dt_ms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
